\chapter{Introduction}

Much of the history of programming languages has been about increasing abstraction
and generalization. Today we take it for granted that a single suitably powerful
language could be used for nearly any development task, were it not for pragmatic
factors beyond our control. Over time, many special-purpose languages (e.g. for
text processing) have been subsumed by these more powerful and general languages.




What do we mean by a \emph{language} for scientific computing?
The prevailing
answer is that it is about numeric arrays, perhaps matrices specifically,
and numerical libraries that use them.
Instead we intend to argue that, at a
deeper level, it is about certain kinds of flexibility, particularly
flexibility in the behavior of key operators and functions. This flexibility
is needed to maximize composability and reusability in scientific code.
Without it, certain programs may be easy to write today, but changing
functional and performance requirements can become difficult to meet.



It is clear that scientific and technical users have their own particular
needs. So far there have been two paths available for fulfilling these
needs: using a mainstream general-purpose language like C++ or Java, or
designing a new language like R or MATLAB. Designing your own language
seems like a drastic thing to do, and yet it is unusually common in
technical computing (see gang of 40).




why integrate code specialization and code selection?

- specialization requires selection anyway
- simpler system
- can sometimes collapse 2 layers of dispatch into 1
- can replace library code with a code generator without either changing
  client code *or* any extra overhead

the key ingredients:

\begin{enumerate}
\item Self-describing data model aware of memory layout
\item Type tags with nested structure
\item A fully-connected type tree
\item Dynamic multiple dispatch over all types % including parameters and varargs
\item Dataflow type inference
\item Automatic code specialization
\end{enumerate}

\begin{figure}
  \label{PLpriorities}
  \begin{center}
    \begin{tabular}{|l|l|}\hline
      \textbf{Mainstream PL} & \textbf{Technical computing} \\
      \hline \hline
      classes, single dispatch             &  complex operators \\
      \hline
      separate compilation                 &  performance, inlining \\
      \hline
      parametric polymorphism              &  ad-hoc polymorphism, extensibility \\
      % - concrete reuse of generated code
      \hline
      static checking                      &  experimental computing \\
      \hline
      modularity, encapsulation            &  large vocabularies \\
      \hline
      eliminating tags                     &  self-describing data, acceptance of tags \\
      \hline
      data hiding                          &  explicit memory layout \\
      \hline
    \end{tabular}
  \end{center}
  \caption{
    Priorities of mainstream object-oriented and functional programming language research and
    implementation compared to those of the technical computing domain.
  }
\end{figure}

Figure~\ref{PLpriorities} compares the general design priorities of mainstream programming
languages to those of technical computing languages. The priorities in each row are not
necessarily opposites or even mutually exclusive, but rather are a matter of emphasis.
For example, it is certainly possible to have both parametric and ad-hoc polymorphism within
the same language, but syntax, recommended idioms, and the design of the standard library will
tend to emphasize one or the other.

It is striking how different these priorities are. We believe these technical factors have
contributed significantly to the persistence of specialized environments in this area.


On "built-in", why built-in is bad. Built-in-ness often conflates two
aspects:

1 - A feature being readily available and agreed-on by all language users
2 - A feature tightly coupled to the rest of the system

(2) implies (1), but not the other way around. (2) is the only technically
interesting item, since the other can be addressed e.g. just by including
a library in the standard software distribution. Many technical computing
languages have done a large amount of (2) while justifying it with point (1).

\section{Contributions}

``One of the most fruitful techniques of language analysis is explication through
elimination. The basic idea is that one explains a linguistic feature by showing
how one could do without it.'' \cite{morris}

A main contribution of this thesis is the application of this approach to features
of technical computing environments that have not been subject to such analysis
before.
