\chapter{Problems in technical computing}

At a high level, the experiences and thoughts that give rise to our
design decisions.

How should a computer scientist approach this space? We might try to
maximize performance. Or it is also easy to make unfounded assumptions about
``what users want''. But instead we should study the real world, see
what is happening and figure out how to steer it in a better direction.

Hypothesis: people don't know what they want. It's also hard to
predict what people will want in the future. We need, in the words
of Gerry Sussman, systems adaptable to uses not imagined by their
designers.

\section{What is a technical computing environment?}

This question has not really been answered.

Views of this are strongly shaped by what systems happen to exist,
and what people were exposed to as they learned to program.

Technical computing software has been designed haphazardly. Each system
is a pile of features taken without argument.




\section{The software stack is too complex}

Collapsing abstraction layers

- for numerical debuggability in particular
- debuggability in general
- no time spent worrying about binding time
- you will build a dynamic dispatch layer anyway, so build it in


How much of the past 30 years of handwritten Matlab internals can
be autogenerated with a compiler? (A lot)

Can now get past traditional classifications of language boundaries
- interpreted vs. compiled, high-level vs. low-level, procedural vs.
imperative vs. functional, etc.

language performance psychology:
if your language doesn't directly support efficient machine data types,
users will rewrite their code in C in order to get them, and then be
happy with the result (though not with the process).

so julia is an all-levels language


\section{Why dynamic typing?}

Mathematical abstractions often frustrate our attempts to represent them
on a computer. For example, mathematicians can move instinctively between
isomorphic objects such as scalars and 1x1 matrices, but most programming
languages would prefer to represent scalars and matrices quite differently.
A system might be able to convert automatically from one to the other, but
it cannot always know which one we *meant*.


\subsection{Operational reasoning}

people tend to think about programs operationally, i.e. what it *does* when
it runs. for example writing
if false
  code
end
the code does not "occur" and therefore does not need to be valid


there is less to learn. with static languages you have to learn what happens
at both compile time and run time, when only run time really matters.


there is a desire to parameterize as much as possible. functions
accept parameters, so function calling ought to be sufficient to express
any desired parameterization.


\subsection{I/O}

inevitably there is a need to refer to a datatype at run time. the best
example is file I/O, where you might want to say "read 500 double-precision
numbers from file X". in static languages the syntax and identifiers used
to specify such run-time types must be different from those used to specify
static types. in C you see defined constants such as \texttt{DATATYPE\_DOUBLE}.


\subsection{Flat metadata hierarchy}

static types are approximations of dynamic types, so languages with static
types inevitably assign two types to a location (both a static type and a
dynamic type) where one would do. in some languages, like C++, the desire
for performance or ease of implementation leads the compiler to make some
decisions based on static types. this is confusing. if type declarations
can be omitted, as in a type-inferred language, the situation is even worse
since the static type of a value might not be apparent.


\subsection{Mismatches with mathematical abstractions}

programs, in general, deal with values of widely varying disjoint types:
functions, numbers, lists, network sockets, etc. type systems
are good at sorting out values of these different types. however, in
mathematical code most values are numbers. numerical properties (such as
positive, negative, even, odd, greater than 1, etc.) are what matter,
and these are highly dynamic. the lattices involved are generally not of
finite height.

different number representations exist only for efficiency, and are often
incidental to the meaning of a piece of code. for example people want
"y = sqrt(x)" to compute the square root of x whether it is positive or
negative, and give a real or complex result accordingly. as another
example, in many cases it is convenient not to need to worry about
integer overflow.


multiple common features underlie mathematical objects of different
types (e.g. numbers, sets, matrices). in some cases it makes sense to
consider numbers and matrices as the same kind of thing, and in other
cases it doesn't matter. A given type system is likely not to have
anticipated the particular common features that matter to your program,
making it more difficult to express an idea. A concrete example is
the matlab fragment
if condition
  idx = ':'
else
  idx = 1
end
where we want to select either an entire dimension or the first position
alone. The ':' and 1 are both indexes in this context, though they would
be of disjoint types in most programming languages.



\section{Bad tradeoffs in current designs}


- Ducking the issue of typing altogether - why this isn't possible IRL

Case in point: Python and NumPy.

NumPy tried to work within the confines of Python, but has more or
less failed for technical and political reasons. (Technical: hard
to work with types in language that deliberately tries to obscure
them from the user. Political: unwillingness to fix broken package
distribution system.) Consequences: Numba and Numba\_lang, Anaconda.
Essentially reinventing types in ``Python''. 

This phenomenon is increasingly noticed in other domains, particularly
JavaScript and web programming. Modern JavaScript implementations are
quite fast, but Google's Dart language is based on the premise that
we could have a web language that is even faster, and offers more
productivity as well. How so? Because Dart's designers observed that
JavaScript programmers in practice often write code that could be
defined using traditional OO classes, but the language does not
support them.

dictionaries for everything (python, js) is the wrong default. almost every
type somebody wants has a fixed number of fields with fixed types.

Python is often described as a good glue language. This
means it is effectively used as an interface standard, a kind of
extended C ABI that makes it easier for libraries to interoperate,
and easier for users to access those libraries. Something as straightforward
as providing a standard N-dimensional numeric array class (NumPy),
which does not exist at the level of C, goes a long way.

However, we wish to point out that in this picture, Python is not
doing as much work as it might first appear. Python does not make
it easier to implement the functionality inside NumPy, or other
``under the hood'' scientific libraries. In many cases it creates
more work, through the need to write wrappers and interfaces
for native code.


Merely being ``dynamic'' (e.g. Python) should not be considered
the gold standard of flexibility. Although these systems permit
tricks that can solve otherwise difficult programming problems,
this is not always the kind of flexibility that is needed.
When faced with the need to describe many functions with elaborate
behavior and many cases, one does not primarily need permissiveness,
but rather powerful and descriptive organizing principles.



How does Julia break through the 4x-slower-than-C performance barrier?

bits types and parameters -- can have abstract types whose size is known
unconditionally




\subsection{What needs to be built in?}

On "built-in", why built-in is bad. Built-in-ness often conflates two
aspects:

\begin{enumerate}
\item A feature being readily available and agreed-on by all language users
\item A feature tightly coupled to the rest of the system
\end{enumerate}

(2) implies (1), but not the other way around. (2) is the only technically
interesting item, since the other can be addressed e.g. just by including
a library in the standard software distribution. Many technical computing
languages have done a large amount of (2) while justifying it with point (1).



While a large part of our motivation is to move more decisions and functionality
into libraries, it is equally important to identify what *must* be part of a
language for the system to be successful. We believe that large amounts of
functionality can be provided by add-ons, but that certain key features
absolutely cannot be. Past failures to properly classify features this way have
caused a lot of undue pain.

First, performance cannot be an add-on. If some users have a fast version of
a language and others have a slow version (with the difference being an
order of magnitude or more), library writers cannot be sure whether users
will find their code fast enough to be useful. How are we to teach people to
program in the language? Courses on MATLAB programming emphasize vectorized code,
but if not all implementations had this performance characteristic the
curriculum would become confused.

Psychologically, it may be difficult to accept a ``non standard'' extension
that changes a language so fundamentally. There is a nagging, though perhaps
totally unfounded, perception that something subtle may break. If indeed a
bug arises due to the use of such an extension, a user is likely to conclude
that the extension is dangerous or broken and stop using it. If, on the other
hand, a bug arises due to a language's standard optimizing compiler, the user
will simply file a bug report, then find a way to work around the problem.

Adding a JIT compiler to a language also requires acceptance of detriments
like compilation pauses and pages with RWX permissions. In some cases this
may lead to use of the extension being disallowed, perhaps for security
reasons.

Type systems similarly fail when provided as optional extensions. Library
writers face the same kinds of problems as with performance add-ons. Should I
use type annotations in my library?

Dynamic dispatch mechanisms also make especially poor add-ons. Of course,
every program makes decisions at run time, and so implements its own
``dispatch'' to some extent. But these behaviors are inextensible; if
language users do not agree on a reusable dispatch framework their code
will not be composable.


\section{Social phenomena}

Programming languages are observed to have strong network effects, and the
difficulty of getting new languages adopted is well known. However based on
[socio PLT paper] we believe this doesn't have to be the case. The formula
of improving or redesigning general-purposes languages to be more appealing to
domain experts might solve the problem. That way the new system has immediate
appeal for at least some users, without the worry that a different tool will
be needed as soon as requirements change slightly.

barrier to contributing

Software business is based on imposing restrictions


Debates about what abstractions mean -- AbstractMatrix
we thought we knew what it meant, but what about something like
SymTridiagonal? It can implement most of what a dense matrix
has, but it can't obey every invariant.

PackedQR
