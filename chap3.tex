\chapter{Design considerations}

At a high level, the experiences and thoughts that give rise to our
design decisions.

How should a computer scientist approach this space? We might try to
maximize performance. Or it is also easy to make unfounded assumptions about
``what users want''. But instead we should study the real world, see
what is happening and figure out how to steer it in a better direction.



\section{The software stack}

Collapsing abstraction layers

- for numerical debuggability in particular
- debuggability in general
- no time spent worrying about binding time
- you will build a dynamic dispatch layer anyway, so build it in


How much of the past 30 years of handwritten Matlab internals can
be autogenerated with a compiler? (A lot)

Can now get past traditional classifications of language boundaries
- interpreted vs. compiled, high-level vs. low-level, procedural vs.
imperative vs. functional, etc.

language performance psychology:
if your language doesn't directly support efficient machine data types,
users will rewrite their code in C in order to get them, and then be
happy with the result (though not with the process).

so julia is an all-levels language


\section{why dynamic typing is popular in technical computing}

Mathematical abstractions often frustrate our attempts to represent them
on a computer. For example, mathematicians can move instinctively between
isomorphic objects such as scalars and 1x1 matrices, but most programming
languages would prefer to represent scalars and matrices quite differently.
A system might be able to convert automatically from one to the other, but
it cannot always know which one we *meant*.


people tend to think about programs operationally, i.e. what it *does* when
it runs. for example writing
if false
  code
end
the code does not "occur" and therefore does not need to be valid


there is less to learn. with static languages you have to learn what happens
at both compile time and run time, when only run time really matters.


there is a desire to parameterize as much as possible. functions
accept parameters, so function calling ought to be sufficient to express
any desired parameterization.


inevitably there is a need to refer to a datatype at run time. the best
example is file I/O, where you might want to say "read 500 double-precision
numbers from file X". in static languages the syntax and identifiers used
to specify such run-time types must be different from those used to specify
static types. in C you see defined constants such as \texttt{DATATYPE\_DOUBLE}.


static types are approximations of dynamic types, so languages with static
types inevitably assign two types to a location (both a static type and a
dynamic type) where one would do. in some languages, like C++, the desire
for performance or ease of implementation leads the compiler to make some
decisions based on static types. this is confusing. if type declarations
can be omitted, as in a type-inferred language, the situation is even worse
since the static type of a value might not be apparent.


programs, in general, deal with values of widely varying disjoint types:
functions, numbers, lists, network sockets, etc. type systems
are good at sorting out values of these different types. however, in
mathematical code most values are numbers. numerical properties (such as
positive, negative, even, odd, greater than 1, etc.) are what matter,
and these are highly dynamic. the lattices involved are generally not of
finite height.


different number representations exist only for efficiency, and are often
incidental to the meaning of a piece of code. for example people want
"y = sqrt(x)" to compute the square root of x whether it is positive or
negative, and give a real or complex result accordingly. as another
example, in many cases it is convenient not to need to worry about
integer overflow.


multiple common features underlie mathematical objects of different
types (e.g. numbers, sets, matrices). in some cases it makes sense to
consider numbers and matrices as the same kind of thing, and in other
cases it doesn't matter. A given type system is likely not to have
anticipated the particular common features that matter to your program,
making it more difficult to express an idea. A concrete example is
the matlab fragment
if condition
  idx = ':'
else
  idx = 1
end
where we want to select either an entire dimension or the first position
alone. The ':' and 1 are both indexes in this context, though they would
be of disjoint types in most programming languages.



\section{Current dynamic languages have bad tradeoffs}


- Ducking the issue of typing altogether - why this isn't possible IRL

Case in point: Python and NumPy.

NumPy tried to work within the confines of Python, but has more or
less failed for technical and political reasons. (Technical: hard
to work with types in language that deliberately tries to obscure
them from the user. Political: unwillingness to fix broken package
distribution system.) Consequences: Numba and Numba\_lang, Anaconda.
Essentially reinventing types in ``Python''. 

This phenomenon is increasingly noticed in other domains, particularly
JavaScript and web programming. Modern JavaScript implementations are
quite fast, but Google's Dart language is based on the premise that
we could have a web language that is even faster, and offers more
productivity as well. How so? Because Dart's designers observed that
JavaScript programmers in practice often write code that could be
defined using traditional OO classes, but the language does not
support them.

dictionaries for everything (python, js) is the wrong default. almost every
type somebody wants has a fixed number of fields with fixed types.


How does Julia break through the 4x-slower-than-C performance barrier?

bits types and parameters -- can have abstract types whose size is known
unconditionally




\section{What needs to be built in?}

While a large part of our motivation is to move more decisions and functionality
into libraries, it is equally important to identify what *must* be part of a
language for the system to be successful. We believe that large amounts of
functionality can be provided by add-ons, but that certain key features
absolutely cannot be. Past failures to properly classify features this way have
caused a lot of undue pain.

First, performance cannot be an add-on. If some users have a fast version of
a language and others have a slow version (with the difference being an
order of magnitude or more), library writers cannot be sure whether users
will find their code fast enough to be useful. How are we to teach people to
program in the language? Courses on MATLAB programming emphasize vectorized code,
but if not all implementations had this performance characteristic the
curriculum would become confused.

Psychologically, it may be difficult to accept a ``non standard'' extension
that changes a language so fundamentally. There is a nagging, though perhaps
totally unfounded, perception that something subtle may break. If indeed a
bug arises due to the use of such an extension, a user is likely to conclude
that the extension is dangerous or broken and stop using it. If, on the other
hand, a bug arises due to a language's standard optimizing compiler, the user
will simply file a bug report, then find a way to work around the problem.

Adding a JIT compiler to a language also requires acceptance of detriments
like compilation pauses and pages with RWX permissions. In some cases this
may lead to use of the extension being disallowed, perhaps for security
reasons.

Type systems similarly fail when provided as optional extensions. Library
writers face the same kinds of problems as with performance add-ons. Should I
use type annotations in my library?

Dynamic dispatch mechanisms also make especially poor add-ons. Of course,
every program makes decisions at run time, and so implements its own
``dispatch'' to some extent. But these behaviors are inextensible; if
language users do not agree on a reusable dispatch framework their code
will not be composable.


\section{Social phenomena}

Programming languages are observed to have strong network effects, and the
difficulty of getting new languages adopted is well known. However based on
[socio PLT paper] we believe this doesn't have to be the case. The formula
of improving or redesigning general-purposes languages to be more appealing to
domain experts might solve the problem. That way the new system has immediate
appeal for at least some users, without the worry that a different tool will
be needed as soon as requirements change slightly.

Software business is based on imposing restrictions

