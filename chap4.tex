\chapter{The Julia Approach}

This chapter will illustrate how we implement key features of technical computing
systems using our methodology.

- The abstractions of equality and comparison. Different equivalence classes between

is/===, isequal and ==

- Numeric vs lexicographic ordering?

cmp, lexcmp, vs isless, <

\section{Numbers}

We might prefer ``number'' to be a single,
concrete concept, but the history of mathematics has seen the concept
extended many times, from integers to rationals to reals, and then to complex,
quaternion, and more. These constructions tend to follow a pattern: a new set
of numbers is constructed around a subset isomorphic to an existing set of
numbers. For example, the reals are isomorphic to the complex numbers with
zero imaginary part.

Human beings happen to be good at equating and moving between isomorphic sets,
so it is easy to imagine that the reals and complexes with zero imaginary
part are one and the same. But a computer forces us to be specific, and admit
that a real number is not complex, and a complex number is not real. And yet
the close relationship between them is too compelling not to model in a
computer somehow. Here we have a numerical analog to the famous ``circle and
ellipse'' problem in object-oriented programming: the set of circles is
isomorphic to the set of ellipses with equal axes, yet neither ``is a''
relationship in a class hierarchy seems fully correct. An ellipse is not
a circle, and in general a circle cannot serve as an ellipse (for example,
the set of circles is not closed under the same operations that the set of
ellipses is, so a program written for ellipses might not work on circles).
This problem implies that a single built-in type hierarchy is not
sufficient: we want to model custom *kinds* of relationships between
types (e.g. ``can be embedded in'' in addition to ``is a'').

Two further problems should also be kept in mind. First, the natural isomorphisms
between sets of numbers might not be isomorphisms on a real computer. For example,
due to the behavior of floating-point arithmetic, an operation on complex numbers
with zero imaginary part might not give an answer equal to the same operation on
real numbers. Second, the contexts that demand use of one type of number or
another are often not easily described by type systems. The classic example is
square root (\texttt{sqrt}), whose result is complex for negative arguments.
Including a number's sign in its type is a possibility, but this quickly gets
out of hand --- should a type system attempt to prove a matrix symmetric before
we compute its eigenvalues? While we cannot offer a once-and-for-all solution
to these problems, we will show how the flexibility of our proposed mechanism
is useful for addressing them.


\subsection{Implementing type embeddings}



\subsection{Current approaches}

Numbers tend to be among the most
complex features of a language. Numeric types usually need to be a special
case: in a typical language with built-in numeric types, describing their
behavior is beyond the expressive power of the language itself. For example,
in C arithmetic operators like \texttt{+} accept multiple types of arguments
(ints and floats), but no user-defined C function can do this (this situation
is of course improved in C++). In Python, a special arrangement is made for
\texttt{+} to call either an \texttt{\_\_add\_\_} or \texttt{\_\_radd\_\_} method,
effectively providing double-dispatch for arithmetic in a language that is
idiomatically single-dispatch.



\section{Arrays}

One-dimensional arrays are a simple and essential data structure found in
most programming languages. The multi-dimensional arrays required in
scientific computing, however, are a different beast entirely. Allowing
any number of dimensions entails a significant increase in complexity. Why?
The essential reason is that core properties of the data structure no
longer fit in a constant amount of space. The space needed to store the
sizes of the dimensions (the array shape) is proportional to the number
of dimensions. This does not seem so bad, but becomes a large problem
due to three additional facts. First, code that operates on the dimension
sizes needs to be highly efficient. Typically the overhead of a loop is
unacceptable, and such code needs to be fully unrolled. Second, in some
code the number of dimensions is a \emph{dynamic} property --- it is
only known at run time. Third, programs may wish to treat arrays with
different numbers of dimensions very differently. A vector (1d) might
have rather different behaviors than a matrix (2d). This kind of
behavior makes the number of dimensions a crucial part of program
semantics, preventing it from remaining a compiler implementation detail.

These facts pull in different directions. The first fact asks for static
analysis. The second fact asks for run-time flexibility. The third fact asks
for dimensionality to be part of the type system, but partly determined
at run time (for example, via virtual method dispatch). Current approaches
choose a compromise. In some systems, the number of dimensions has a strict
limit (e.g. 3 or 4), so that separate classes for each case may be written
out in full. Other systems choose flexibility, and just accept that most
or all operations will be dynamically dispatched. Other systems might
provide flexibility only at compile time, for example a template library
where the number of dimensions must be statically known.

Whatever decision is made, rules must be defined for how various operators
act on dimensions. For now we will focus on indexing, since selecting
parts of arrays has particularly rich behavior with respect to
dimensionality. For example, if a single row or column of a matrix is
selected, does the result have one or two dimensions? Array implementations
prefer to invoke general rules to answer such questions. Such a rule might
say ``dimensions indexed with scalars are dropped'', or ``trailing
dimensions of size one are dropped'', or ``the rank of the result
is the sum of the ranks of the indexes'' (as in APL).

How are such rules implemented? For a
language with built-in multidimensional arrays, the compiler will
analyze indexing expressions and determine an answer using hard-coded
logic. However, this approach is not satisfying: we would rather
implement the behavior in libraries, so that different kinds of arrays
may be defined, or so that rules of similar complexity may be
defined for other kinds of objects. But these kinds of rules are
unusually difficult to implement in libraries. If a library writes out
its indexing logic using imperative code, the host language compiler
is not likely to be able to analyze it. Using compile-time abstracton
(templates) would provide better performance, but such libraries tend
to be difficult to write (and read), and the full complement of
indexing behavior expected by technical users strains the capabilities
of such systems.

Our dispatch mechanism permits a novel solution. If a multiple dispatch
system supports variadic functions and argument ``splicing'' (the ability
to pass a structure of $n$ values as $n$ separate arguments to a function),
then indexing behavior can be defined as method signatures.

Below we define a function \texttt{index\_shape} that computes the
shape of a result array given a series of index arguments. There are
three versions, each implementing a different rule that users in
different domains might want:

\begin{verbatim}
# drop dimensions indexed with scalars
index_shape() = ()
index_shape(i::Real, I...) = index_shape(I...)
index_shape(i, I...) = tuple(length(i), index_shape(I...)...)
\end{verbatim}

\begin{verbatim}
# drop trailing dimensions indexed with scalars
index_shape(i::Real...) = ()
index_shape(i, I...) = tuple(length(i), index_shape(I...)...)
\end{verbatim}

\begin{verbatim}
# rank summing (APL)
index_shape() = ()
index_shape(i, I...) = tuple(size(i)..., index_shape(I...)...)
\end{verbatim}

Inferring the length of the result of \texttt{index\_shape} is sufficient
to infer the rank of the result array.

These definitions are concise, easy to write, and possible for a
compiler to understand fully using straightforward techniques.

Here is a sample derivation for the call \texttt{index\_shape(1:m,1,1:n)}
(the argument type tuple is \texttt{(Range1,Int,Range1)}), using the first
definition above (drop scalars):

\begin{verbatim}
index_shape(1:n, 1, 1:m) => tuple(length(::Range1)::Int, index_shape((::Int, ::Range1)...)...)

index_shape((::Int, ::Range1)...) => index_shape(::Int, ::Range1)

index_shape(::Int, ::Range1) => index_shape((::Range1,)...)

index_shape((::Range1,)...) => index_shape(::Range1)

index_shape(::Range1) => tuple(length(::Range1)::Int, index_shape(()...)...)

index_shape(()...) => index_shape()::()

back substitute => tuple(length(::Range1)::Int, index_shape(()...)::()...)::(Int,)

back substitute => tuple(length(::Range1)::Int, ::(Int,)...)

tuple(::Int, ::(Int,)...) => tuple(::Int, ::Int)

::(Int, Int)

\end{verbatim}

The result type is determined using only dataflow type inference, plus a
rule for splicing an immediate container (the type of \texttt{f((a,b)...)} is
the type of \texttt{f(a,b)}). Argument list destructuring takes place inside
the type intersection operator used to combine argument types with method
signatures.

This approach does not depend on any heuristics. Each call to \texttt{index\_shape}
simply requires one recursive invocation of type inference. This process reaches
the base case \texttt{()} for these definitions, since each recursive call
handles a shorter argument list (for less-well-behaved definitions, we might
end up invoking a widening operator instead).


\begin{verbatim}
diverge() = randbool() ? () : tuple(1, diverge()...)
\end{verbatim}



\section{Units}

